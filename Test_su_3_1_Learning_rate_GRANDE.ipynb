{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_su_3.1_Learning_rate_GRANDE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMDigTVUTyq9PdMTFioFbd6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaoloRusso137/Test_su_3.1_Learning_rate_GRANDE/blob/main/Test_su_3_1_Learning_rate_GRANDE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DodocOsr-TxJ",
        "outputId": "81a35f0c-482e-4f04-a4be-5d71d61ad350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DA FARE SOLO LA PRIMA VOLTA SE NON C'è LA CARTELLA Project_DAAI\n",
        "#!git clone https://github.com/PaoloRusso137/Project_DAAI.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0iO9DRPBGsE",
        "outputId": "b4b6f99b-c83f-4313-b341-202af1a5f9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Project_DAAI' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DA FARE SOLO LA PRIMA VOLTA SE NON C'è LA CARTELLA Project_DAAI\n",
        "#!mv \"/content/Project_DAAI\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "ZVMHz8oUBfyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/pitts30k.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTU-P5o4CcxM",
        "outputId": "6cd2926b-3349-4368-9f2c-4b806b7f181f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pitts30k/pitts30k  #Create a new folder called pitts30k inside the already existing pitts30k\n",
        "!mv \"/content/pitts30k/images\" \"/content/pitts30k/pitts30k\" #The train file requires two folder named pitts30k"
      ],
      "metadata": {
        "id": "WZUHjSq2DVca"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/pitts30k/pitts30k/pitts30k   #Create a new folder called pitts30k inside the already existing pitts30k"
      ],
      "metadata": {
        "id": "Ta_6UHhvFuZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"/content/pitts30k/pitts30k/images\" \"/content/pitts30k/pitts30k/pitts30k\" #The train file requires two folder named pitts30k"
      ],
      "metadata": {
        "id": "HWrj7aEhF2n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzPf4aF2EuzO",
        "outputId": "174efe69-2d80-4736-bea0-54f03da24dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Project_DAAI\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUtOnarrEw6a",
        "outputId": "41ccf433-ab04-424b-feb5-4be22817e2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project_DAAI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss_cpu==1.7.1\n",
        "!pip install numpy==1.19.4\n",
        "!pip install Pillow==8.4.0\n",
        "!pip install scikit_learn==1.0.1\n",
        "!pip install torch==1.7.0\n",
        "!pip install torchvision==0.8.1\n",
        "!pip install tqdm==4.48.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fE770awHEz_N",
        "outputId": "42492e04-4a96-4aed-bddd-64d52f1f7e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss_cpu==1.7.1\n",
            "  Downloading faiss_cpu-1.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 8.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.1\n",
            "Collecting numpy==1.19.4\n",
            "  Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 8.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow==8.4.0\n",
            "  Downloading Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 12.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-8.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit_learn==1.0.1 in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.19.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.4.1)\n",
            "Collecting torch==1.7.0\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.3 kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.10.0.2)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n",
            "Collecting torchvision==0.8.1\n",
            "  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.19.4)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.7.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (3.10.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "Successfully installed torchvision-0.8.1\n",
            "Collecting tqdm==4.48.2\n",
            "  Downloading tqdm-4.48.2-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tqdm-4.48.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"train.py\" --datasets_folder \"/content/pitts30k/pitts30k\" --lr 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcyUbHD5F5Eg",
        "outputId": "b9cad2c1-b649-418d-89de-ef4337d80812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-05 16:46:03   Arguments: Namespace(cache_refresh_rate=1000, datasets_folder='/content/pitts30k/pitts30k', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=0.0001, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_workers=8, output_folder='runs/default/2022-01-05_16-46-03', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, val_positive_dist_threshold=25)\n",
            "2022-01-05 16:46:03   The outputs are being saved in runs/default/2022-01-05_16-46-03\n",
            "2022-01-05 16:46:03   Using 1 GPUs and 2 CPUs\n",
            "2022-01-05 16:46:03   Loading dataset Pitts30k from folder /content/pitts30k/pitts30k\n",
            "2022-01-05 16:46:04   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "2022-01-05 16:46:04   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >\n",
            "2022-01-05 16:46:04   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >\n",
            "2022-01-05 16:46:04   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 71.8MB/s]\n",
            "2022-01-05 16:46:05   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones\n",
            "2022-01-05 16:46:07   Output dimension of the model is 256\n",
            "2022-01-05 16:46:07   Start training epoch: 00\n",
            "2022-01-05 16:46:07   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.90it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 821.44it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:44<00:00,  1.14s/it]\n",
            "2022-01-05 16:53:50   Epoch[00](0/5): current batch triplet loss = 0.0225, average epoch triplet loss = 0.0401\n",
            "2022-01-05 16:53:50   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 823.67it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:41<00:00,  1.13s/it]\n",
            "2022-01-05 17:01:29   Epoch[00](1/5): current batch triplet loss = 0.0262, average epoch triplet loss = 0.0334\n",
            "2022-01-05 17:01:29   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 839.82it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:43<00:00,  1.13s/it]\n",
            "2022-01-05 17:09:12   Epoch[00](2/5): current batch triplet loss = 0.0208, average epoch triplet loss = 0.0280\n",
            "2022-01-05 17:09:12   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 811.25it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:41<00:00,  1.12s/it]\n",
            "2022-01-05 17:16:52   Epoch[00](3/5): current batch triplet loss = 0.0180, average epoch triplet loss = 0.0249\n",
            "2022-01-05 17:16:52   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 828.06it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 17:24:31   Epoch[00](4/5): current batch triplet loss = 0.0400, average epoch triplet loss = 0.0226\n",
            "2022-01-05 17:24:31   Finished epoch 00 in 0:38:24, average epoch triplet loss = 0.0226\n",
            "2022-01-05 17:24:31   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:41<00:00,  3.88it/s]\n",
            "2022-01-05 17:27:13   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:02<00:00,  3.88it/s]\n",
            "2022-01-05 17:29:15   Calculating recalls\n",
            "2022-01-05 17:29:17   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 78.1, R@5: 90.5, R@10: 93.8, R@20: 96.3\n",
            "2022-01-05 17:29:17   Improved: previous best R@5 = 0.0, current R@5 = 90.5\n",
            "2022-01-05 17:29:17   Start training epoch: 01\n",
            "2022-01-05 17:29:17   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 815.23it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:42<00:00,  1.13s/it]\n",
            "2022-01-05 17:36:57   Epoch[01](0/5): current batch triplet loss = 0.0172, average epoch triplet loss = 0.0106\n",
            "2022-01-05 17:36:57   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 815.86it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:42<00:00,  1.13s/it]\n",
            "2022-01-05 17:44:38   Epoch[01](1/5): current batch triplet loss = 0.0157, average epoch triplet loss = 0.0102\n",
            "2022-01-05 17:44:38   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 819.92it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:41<00:00,  1.13s/it]\n",
            "2022-01-05 17:52:19   Epoch[01](2/5): current batch triplet loss = 0.0059, average epoch triplet loss = 0.0094\n",
            "2022-01-05 17:52:19   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.91it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 817.96it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:44<00:00,  1.14s/it]\n",
            "2022-01-05 18:00:01   Epoch[01](3/5): current batch triplet loss = 0.0156, average epoch triplet loss = 0.0091\n",
            "2022-01-05 18:00:01   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 812.64it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:42<00:00,  1.13s/it]\n",
            "2022-01-05 18:07:42   Epoch[01](4/5): current batch triplet loss = 0.0090, average epoch triplet loss = 0.0088\n",
            "2022-01-05 18:07:42   Finished epoch 01 in 0:38:25, average epoch triplet loss = 0.0088\n",
            "2022-01-05 18:07:42   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:42<00:00,  3.84it/s]\n",
            "2022-01-05 18:10:25   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:04<00:00,  3.83it/s]\n",
            "2022-01-05 18:12:29   Calculating recalls\n",
            "2022-01-05 18:12:31   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 78.7, R@5: 91.4, R@10: 94.6, R@20: 97.0\n",
            "2022-01-05 18:12:31   Improved: previous best R@5 = 90.5, current R@5 = 91.4\n",
            "2022-01-05 18:12:31   Start training epoch: 02\n",
            "2022-01-05 18:12:31   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 769.57it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:42<00:00,  1.13s/it]\n",
            "2022-01-05 18:20:14   Epoch[02](0/5): current batch triplet loss = 0.0024, average epoch triplet loss = 0.0061\n",
            "2022-01-05 18:20:14   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 824.80it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:42<00:00,  1.13s/it]\n",
            "2022-01-05 18:27:55   Epoch[02](1/5): current batch triplet loss = 0.0050, average epoch triplet loss = 0.0059\n",
            "2022-01-05 18:27:55   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.85it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 809.12it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:43<00:00,  1.13s/it]\n",
            "2022-01-05 18:35:38   Epoch[02](2/5): current batch triplet loss = 0.0014, average epoch triplet loss = 0.0058\n",
            "2022-01-05 18:35:38   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 826.66it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:44<00:00,  1.14s/it]\n",
            "2022-01-05 18:43:22   Epoch[02](3/5): current batch triplet loss = 0.0032, average epoch triplet loss = 0.0056\n",
            "2022-01-05 18:43:22   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 789.28it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:42<00:00,  1.13s/it]\n",
            "2022-01-05 18:51:03   Epoch[02](4/5): current batch triplet loss = 0.0025, average epoch triplet loss = 0.0054\n",
            "2022-01-05 18:51:03   Finished epoch 02 in 0:38:31, average epoch triplet loss = 0.0054\n",
            "2022-01-05 18:51:03   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:43<00:00,  3.83it/s]\n",
            "2022-01-05 18:53:46   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:03<00:00,  3.84it/s]\n",
            "2022-01-05 18:55:50   Calculating recalls\n",
            "2022-01-05 18:55:52   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 79.0, R@5: 91.4, R@10: 94.7, R@20: 97.0\n",
            "2022-01-05 18:55:52   Not improved: 1 / 3: best R@5 = 91.4, current R@5 = 91.4\n",
            "2022-01-05 18:55:52   Start training epoch: 03\n",
            "2022-01-05 18:55:52   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.85it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 808.13it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:49<00:00,  1.16s/it]\n",
            "2022-01-05 19:03:42   Epoch[03](0/5): current batch triplet loss = 0.0019, average epoch triplet loss = 0.0044\n",
            "2022-01-05 19:03:42   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 813.32it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:42<00:00,  1.13s/it]\n",
            "2022-01-05 19:11:23   Epoch[03](1/5): current batch triplet loss = 0.0025, average epoch triplet loss = 0.0046\n",
            "2022-01-05 19:11:23   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 818.86it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:42<00:00,  1.13s/it]\n",
            "2022-01-05 19:19:04   Epoch[03](2/5): current batch triplet loss = 0.0031, average epoch triplet loss = 0.0044\n",
            "2022-01-05 19:19:04   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 821.15it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:39<00:00,  1.12s/it]\n",
            "2022-01-05 19:26:42   Epoch[03](3/5): current batch triplet loss = 0.0011, average epoch triplet loss = 0.0043\n",
            "2022-01-05 19:26:42   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.91it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 817.57it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 19:34:19   Epoch[03](4/5): current batch triplet loss = 0.0058, average epoch triplet loss = 0.0043\n",
            "2022-01-05 19:34:19   Finished epoch 03 in 0:38:27, average epoch triplet loss = 0.0043\n",
            "2022-01-05 19:34:19   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:40<00:00,  3.89it/s]\n",
            "2022-01-05 19:37:00   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:04<00:00,  3.84it/s]\n",
            "2022-01-05 19:39:04   Calculating recalls\n",
            "2022-01-05 19:39:06   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 78.3, R@5: 90.5, R@10: 93.8, R@20: 96.3\n",
            "2022-01-05 19:39:06   Not improved: 2 / 3: best R@5 = 91.4, current R@5 = 90.5\n",
            "2022-01-05 19:39:06   Start training epoch: 04\n",
            "2022-01-05 19:39:06   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.90it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 802.25it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 19:46:44   Epoch[04](0/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0042\n",
            "2022-01-05 19:46:44   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 838.98it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 19:54:23   Epoch[04](1/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0042\n",
            "2022-01-05 19:54:23   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 824.55it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 20:02:03   Epoch[04](2/5): current batch triplet loss = 0.0118, average epoch triplet loss = 0.0042\n",
            "2022-01-05 20:02:03   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 825.87it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:41<00:00,  1.12s/it]\n",
            "2022-01-05 20:09:42   Epoch[04](3/5): current batch triplet loss = 0.0118, average epoch triplet loss = 0.0042\n",
            "2022-01-05 20:09:42   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 821.83it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 20:17:21   Epoch[04](4/5): current batch triplet loss = 0.0010, average epoch triplet loss = 0.0042\n",
            "2022-01-05 20:17:21   Finished epoch 04 in 0:38:15, average epoch triplet loss = 0.0042\n",
            "2022-01-05 20:17:21   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:42<00:00,  3.85it/s]\n",
            "2022-01-05 20:20:04   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:03<00:00,  3.85it/s]\n",
            "2022-01-05 20:22:07   Calculating recalls\n",
            "2022-01-05 20:22:09   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 79.2, R@5: 91.8, R@10: 95.0, R@20: 97.1\n",
            "2022-01-05 20:22:09   Improved: previous best R@5 = 91.4, current R@5 = 91.8\n",
            "2022-01-05 20:22:09   Start training epoch: 05\n",
            "2022-01-05 20:22:09   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 811.44it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:42<00:00,  1.13s/it]\n",
            "2022-01-05 20:29:50   Epoch[05](0/5): current batch triplet loss = 0.0043, average epoch triplet loss = 0.0043\n",
            "2022-01-05 20:29:50   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 847.58it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 20:37:29   Epoch[05](1/5): current batch triplet loss = 0.0020, average epoch triplet loss = 0.0042\n",
            "2022-01-05 20:37:29   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 807.45it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 20:45:07   Epoch[05](2/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0040\n",
            "2022-01-05 20:45:07   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 815.04it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:41<00:00,  1.12s/it]\n",
            "2022-01-05 20:52:47   Epoch[05](3/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0039\n",
            "2022-01-05 20:52:47   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 816.06it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:42<00:00,  1.13s/it]\n",
            "2022-01-05 21:00:29   Epoch[05](4/5): current batch triplet loss = 0.0077, average epoch triplet loss = 0.0040\n",
            "2022-01-05 21:00:29   Finished epoch 05 in 0:38:19, average epoch triplet loss = 0.0040\n",
            "2022-01-05 21:00:29   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:42<00:00,  3.85it/s]\n",
            "2022-01-05 21:03:11   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:03<00:00,  3.85it/s]\n",
            "2022-01-05 21:05:15   Calculating recalls\n",
            "2022-01-05 21:05:16   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 78.8, R@5: 91.9, R@10: 94.9, R@20: 97.3\n",
            "2022-01-05 21:05:17   Improved: previous best R@5 = 91.8, current R@5 = 91.9\n",
            "2022-01-05 21:05:17   Start training epoch: 06\n",
            "2022-01-05 21:05:17   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 815.65it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:43<00:00,  1.13s/it]\n",
            "2022-01-05 21:12:59   Epoch[06](0/5): current batch triplet loss = 0.0048, average epoch triplet loss = 0.0041\n",
            "2022-01-05 21:12:59   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 785.10it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 21:20:39   Epoch[06](1/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0037\n",
            "2022-01-05 21:20:39   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 796.32it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:41<00:00,  1.13s/it]\n",
            "2022-01-05 21:28:19   Epoch[06](2/5): current batch triplet loss = 0.0025, average epoch triplet loss = 0.0038\n",
            "2022-01-05 21:28:19   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 830.62it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:42<00:00,  1.13s/it]\n",
            "2022-01-05 21:36:00   Epoch[06](3/5): current batch triplet loss = 0.0033, average epoch triplet loss = 0.0039\n",
            "2022-01-05 21:36:00   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 813.51it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:41<00:00,  1.13s/it]\n",
            "2022-01-05 21:43:41   Epoch[06](4/5): current batch triplet loss = 0.0025, average epoch triplet loss = 0.0040\n",
            "2022-01-05 21:43:41   Finished epoch 06 in 0:38:24, average epoch triplet loss = 0.0040\n",
            "2022-01-05 21:43:41   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:41<00:00,  3.87it/s]\n",
            "2022-01-05 21:46:23   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:03<00:00,  3.85it/s]\n",
            "2022-01-05 21:48:27   Calculating recalls\n",
            "2022-01-05 21:48:28   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 79.7, R@5: 92.3, R@10: 95.4, R@20: 97.7\n",
            "2022-01-05 21:48:28   Improved: previous best R@5 = 91.9, current R@5 = 92.3\n",
            "2022-01-05 21:48:28   Start training epoch: 07\n",
            "2022-01-05 21:48:28   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 834.21it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:44<00:00,  1.14s/it]\n",
            "2022-01-05 21:56:11   Epoch[07](0/5): current batch triplet loss = 0.0029, average epoch triplet loss = 0.0042\n",
            "2022-01-05 21:56:11   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:55<00:00,  3.92it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 832.77it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:43<00:00,  1.13s/it]\n",
            "2022-01-05 22:03:51   Epoch[07](1/5): current batch triplet loss = 0.0032, average epoch triplet loss = 0.0039\n",
            "2022-01-05 22:03:51   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 825.65it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 22:11:29   Epoch[07](2/5): current batch triplet loss = 0.0025, average epoch triplet loss = 0.0038\n",
            "2022-01-05 22:11:29   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 835.25it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 22:19:08   Epoch[07](3/5): current batch triplet loss = 0.0050, average epoch triplet loss = 0.0037\n",
            "2022-01-05 22:19:08   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.90it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 823.21it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:39<00:00,  1.12s/it]\n",
            "2022-01-05 22:26:46   Epoch[07](4/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0036\n",
            "2022-01-05 22:26:46   Finished epoch 07 in 0:38:17, average epoch triplet loss = 0.0036\n",
            "2022-01-05 22:26:46   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:41<00:00,  3.87it/s]\n",
            "2022-01-05 22:29:27   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:03<00:00,  3.85it/s]\n",
            "2022-01-05 22:31:31   Calculating recalls\n",
            "2022-01-05 22:31:32   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 78.8, R@5: 92.0, R@10: 95.1, R@20: 97.5\n",
            "2022-01-05 22:31:32   Not improved: 1 / 3: best R@5 = 92.3, current R@5 = 92.0\n",
            "2022-01-05 22:31:32   Start training epoch: 08\n",
            "2022-01-05 22:31:32   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.91it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 828.00it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 22:39:10   Epoch[08](0/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0041\n",
            "2022-01-05 22:39:10   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 831.39it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 22:46:50   Epoch[08](1/5): current batch triplet loss = 0.0036, average epoch triplet loss = 0.0040\n",
            "2022-01-05 22:46:50   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.90it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 828.28it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:41<00:00,  1.13s/it]\n",
            "2022-01-05 22:54:30   Epoch[08](2/5): current batch triplet loss = 0.0014, average epoch triplet loss = 0.0039\n",
            "2022-01-05 22:54:30   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.90it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 822.75it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 23:02:08   Epoch[08](3/5): current batch triplet loss = 0.0025, average epoch triplet loss = 0.0039\n",
            "2022-01-05 23:02:08   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 832.68it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:39<00:00,  1.12s/it]\n",
            "2022-01-05 23:09:46   Epoch[08](4/5): current batch triplet loss = 0.0074, average epoch triplet loss = 0.0039\n",
            "2022-01-05 23:09:46   Finished epoch 08 in 0:38:14, average epoch triplet loss = 0.0039\n",
            "2022-01-05 23:09:46   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:42<00:00,  3.85it/s]\n",
            "2022-01-05 23:12:29   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:02<00:00,  3.88it/s]\n",
            "2022-01-05 23:14:32   Calculating recalls\n",
            "2022-01-05 23:14:33   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 79.8, R@5: 92.2, R@10: 95.1, R@20: 97.3\n",
            "2022-01-05 23:14:33   Not improved: 2 / 3: best R@5 = 92.3, current R@5 = 92.2\n",
            "2022-01-05 23:14:33   Start training epoch: 09\n",
            "2022-01-05 23:14:33   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 832.68it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:46<00:00,  1.15s/it]\n",
            "2022-01-05 23:22:18   Epoch[09](0/5): current batch triplet loss = 0.0028, average epoch triplet loss = 0.0037\n",
            "2022-01-05 23:22:18   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:55<00:00,  3.91it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 842.84it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:39<00:00,  1.12s/it]\n",
            "2022-01-05 23:29:55   Epoch[09](1/5): current batch triplet loss = 0.0037, average epoch triplet loss = 0.0037\n",
            "2022-01-05 23:29:55   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 834.21it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:41<00:00,  1.12s/it]\n",
            "2022-01-05 23:37:34   Epoch[09](2/5): current batch triplet loss = 0.0002, average epoch triplet loss = 0.0037\n",
            "2022-01-05 23:37:34   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 830.22it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 23:45:13   Epoch[09](3/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0038\n",
            "2022-01-05 23:45:13   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 842.07it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-05 23:52:54   Epoch[09](4/5): current batch triplet loss = 0.0079, average epoch triplet loss = 0.0038\n",
            "2022-01-05 23:52:54   Finished epoch 09 in 0:38:20, average epoch triplet loss = 0.0038\n",
            "2022-01-05 23:52:54   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:42<00:00,  3.85it/s]\n",
            "2022-01-05 23:55:36   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:03<00:00,  3.85it/s]\n",
            "2022-01-05 23:57:39   Calculating recalls\n",
            "2022-01-05 23:57:41   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 79.2, R@5: 91.8, R@10: 94.7, R@20: 97.0\n",
            "2022-01-05 23:57:41   Not improved: 3 / 3: best R@5 = 92.3, current R@5 = 91.8\n",
            "2022-01-05 23:57:41   Performance did not improve for 3 epochs. Stop training.\n",
            "2022-01-05 23:57:41   Best R@5: 92.3\n",
            "2022-01-05 23:57:41   Trained for 10 epochs, in total in 7:11:38\n",
            "2022-01-05 23:57:41   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:42<00:00,  3.86it/s]\n",
            "2022-01-06 00:00:23   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 426/426 [01:50<00:00,  3.84it/s]\n",
            "2022-01-06 00:02:14   Calculating recalls\n",
            "2022-01-06 00:02:16   Recalls on < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >: R@1: 79.0, R@5: 90.1, R@10: 93.4, R@20: 95.3\n"
          ]
        }
      ]
    }
  ]
}